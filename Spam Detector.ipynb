{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tofu/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/tofu/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f333d0c2710>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import _pickle as cPickle\n",
    "import sys\n",
    "from wordcloud import WordCloud\n",
    "import seaborn\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix,roc_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB,MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "spam_data = pd.read_csv(\"spam.csv\",encoding = \"latin1\")\n",
    "spam_data.rename(columns={'v1':'label','v2':'message'},inplace = True)\n",
    "spam_data = spam_data[[\"label\",\"message\"]]\n",
    "spam_data[\"label\"] = spam_data[\"label\"].apply(lambda x: 0 if(x==\"ham\") else 1)\n",
    "\n",
    "spam_data[\"length\"] = spam_data[\"message\"].map(lambda text:len(text))\n",
    "spam_data_labels = spam_data[\"label\"]\n",
    "spam_data_value = spam_data[\"message\"]\n",
    "spam_data_value = spam_data_value.str.lower()\n",
    "X_train, X_test,y_train,y_test = train_test_split(spam_data_value,spam_data_labels,random_state=0)\n",
    "\n",
    "# spam_data.length.plot(bins=20,kind=\"hist\")\n",
    "\n",
    "# spam_data.hist(column = \"length\",bins=20,by = \"v1\")\n",
    "# plt.show()\n",
    "# def ensureUtf(s):\n",
    "#     try:\n",
    "#         if type(s) == unicode:\n",
    "#             return s.encode('utf8', 'ignore')\n",
    "#     except: \n",
    "#             return str(s)\n",
    "\n",
    "spam_words = ' '.join(list(spam_data[spam_data['label']==1][\"message\"]))\n",
    "spam_wc = WordCloud(width=512,height=512).generate(spam_words)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.imshow(spam_wc)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "non_spam_words = ' '.join(list(spam_data[spam_data['label']==0][\"message\"]))\n",
    "non_spam_wc = WordCloud(width=512,height=512).generate(non_spam_words)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.imshow(non_spam_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vect = TfidfVectorizer(min_df=5,stop_words = 'english',analyzer='char_wb',ngram_range = (1,3)).fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.9901890404402968\n"
     ]
    }
   ],
   "source": [
    "X_train_transform = vect.transform(X_train)\n",
    "X_test_transform = vect.transform(X_test)\n",
    "# clf = SVC(C=10000).fit(X_train_transform,y_train)\n",
    "# pred = clf.predict(X_test_transform)\n",
    "# auc_score = roc_auc_score(y_test,pred)\n",
    "param = [{'C':[10,100,1000,10000],'kernel':['linear']},\n",
    "                {'C':[1,10,100,1000,10000], 'gamma':[0.0001,0.001],'kernel':['rbf']}]\n",
    "clf = GridSearchCV(SVC(),param_grid = param, cv = 5)\n",
    "clf.fit(X_train_transform,y_train)\n",
    "# confusion_matrix = confusion_matrix(y_test,pred)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "# d = list(pd.read_table(\"test.txt\"))\n",
    "# clf.predict(vect.transform(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9754851196034158\n"
     ]
    }
   ],
   "source": [
    "spam_detector = SVC(C=10000,gamma=0.001,kernel='rbf').fit(X_train_transform,y_train)\n",
    "prediction = spam_detector.predict(X_test_transform)\n",
    "auc_score = roc_auc_score(y_test,prediction)\n",
    "print(auc_score)\n",
    "\n",
    "with open('spam_detector.pkl','wb') as fout:\n",
    "    cPickle.dump(spam_detector,fout)\n",
    "spam_detector_reloaded = cPickle.load(open('spam_detector.pkl','rb'))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3b426be73766>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(spam_detector.predict(vect.transform(i)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mspam_detector_reloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'transform' is not defined"
     ]
    }
   ],
   "source": [
    "# input_file = sys.argv[1]\n",
    "# i = list(pd.read_table(input_file))\n",
    "# print(spam_detector.predict(vect.transform(i)))\n",
    "d = list(pd.read_table(\"test.txt\"))\n",
    "spam_detector_reloaded.predict(transform(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
